# Ollama server endpoint
OLLAMA_BASE_URL=http://localhost:11434

# Default LLM used for initial system settings seed
OLLAMA_MODEL=llama3.1:8b

# Embedding models (admin can switch in Setting & Help)
# all-MiniLM-L6-v2 (HuggingFace) or nomic-embed-text (Ollama)
DEFAULT_EMBEDDING_MODEL=all-MiniLM-L6-v2

# Ollama embedding model name (used when selecting nomic embedding)
OLLAMA_EMBED_MODEL=nomic-embed-text

# HuggingFace embedding model repo (used when selecting MiniLM embedding)
HF_EMBED_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Storage paths
UPLOAD_DIR=data/uploads
CHROMA_PERSIST_DIR=data/chroma_db

# Retrieval defaults
TOP_K=4
CHUNK_SIZE=512
CHUNK_OVERLAP=80
TEMPERATURE=0.2
